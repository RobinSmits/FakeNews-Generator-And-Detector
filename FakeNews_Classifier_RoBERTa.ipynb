{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNews_Classifier_RoBERTa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPbhISxkGfncCz+MxARhHLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "042381bac88044ddb377384a23c45d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9975b699b304dcf86da83269d80821a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_014e8adcb70045549f5dd953b690ef4e",
              "IPY_MODEL_25d0f27580784cf999ba635a058fd9d3"
            ]
          }
        },
        "e9975b699b304dcf86da83269d80821a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "014e8adcb70045549f5dd953b690ef4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_576de57bd46d4a87bfc939ee1bd2cd8b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 48000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 48000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5e6f118ac834b1daa9f96a54dc07bc2"
          }
        },
        "25d0f27580784cf999ba635a058fd9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_610c88b795ea4e139f59ec7ace281e73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 48000/48000 [00:55&lt;00:00, 861.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_831f7bf0a15d474b90aec3f2ee8c0503"
          }
        },
        "576de57bd46d4a87bfc939ee1bd2cd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5e6f118ac834b1daa9f96a54dc07bc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "610c88b795ea4e139f59ec7ace281e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "831f7bf0a15d474b90aec3f2ee8c0503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5cb099e47fd463baa3eba394fb2f20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf0f2e2fd39f4114b1c8fda85311a515",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a7c13c71184541f48972ae1bdd00f45d",
              "IPY_MODEL_7c026b8f0a6145c7be1db6999674cb4a"
            ]
          }
        },
        "bf0f2e2fd39f4114b1c8fda85311a515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7c13c71184541f48972ae1bdd00f45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73bdb7cbf5314656b4b361902e416727",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 12000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca272e5ee2464b72a0645e5d21417611"
          }
        },
        "7c026b8f0a6145c7be1db6999674cb4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b06ab290d4940539cb0a46e3c07b721",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12000/12000 [00:10&lt;00:00, 1169.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_153b0d34898542659b56a418f97cdb88"
          }
        },
        "73bdb7cbf5314656b4b361902e416727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca272e5ee2464b72a0645e5d21417611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b06ab290d4940539cb0a46e3c07b721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "153b0d34898542659b56a418f97cdb88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobinSmits/FakeNews-Generator-And-Detector/blob/main/FakeNews_Classifier_RoBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Su4OWsMnM2T"
      },
      "source": [
        "In the first notebook we used a T5 model to train on the 'title' and 'description' of the 'ag_news_subset' dataset. As a second step we used that T5 model to generate a CSV with fake news based on the input 'title'.\n",
        "\n",
        "In this second notebook we will use the real and fake news in the generated csv ('generated_fake_news.csv') file to train a RoBERTa Base model to classify the real (column: 'description' - label: 0) or fake news (column: 'generated' - label: 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFLz1oijbeuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222e37e5-bb44-41dc-d87d-34b7cf18cd97"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Install Specific Versions\n",
        "!pip install tensorflow==2.3.1\n",
        "!pip install tensorflow-datasets==4.1.0\n",
        "!pip install transformers==4.0.0\n",
        "!pip install sentencepiece==0.1.94\n",
        "\n",
        "# Import Packages\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import *\n",
        "import sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.6.3)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.33.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (3.12.4)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (50.3.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.4.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2020.11.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-datasets==4.1.0 in /usr/local/lib/python3.6/dist-packages (4.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (4.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.25.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.8)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (20.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (1.18.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (2.3)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.1.0) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.1.0) (3.0.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.1.0) (1.52.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==4.1.0) (50.3.2)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets==4.1.0) (3.4.0)\n",
            "Requirement already satisfied: transformers==4.0.0 in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2020.11.8)\n",
            "Requirement already satisfied: sentencepiece==0.1.94 in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viZcqIFVpBy4"
      },
      "source": [
        "I've created and tested these notebooks on Google Colab Pro and used Google Drive to store and load any files created. \n",
        "\n",
        "If you run the code locally on a computer then modify the 'WORK_DIR' accordingly. Google Drive will not be needed in that case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RjCDJ7YzUdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c247e9fe-1b92-436d-8eb4-a219d11e7716"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set Folder to use...\n",
        "WORK_DIR = '/content/drive/My Drive/fake_news/'\n",
        "os.makedirs(WORK_DIR, exist_ok = True) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFcrPFEcpc0y"
      },
      "source": [
        "Next we set some config for the device to use (Note: TPU to be added/tested in the future.) We also set the necessary constants. \n",
        "\n",
        "For the learning rate you could try different settings. Setting the learning rate to high will very quickly overfit the model\n",
        "\n",
        "And finally we set the RoBERTa tokenizer and config to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7jUGKre059v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c960ef56-ac32-4e1f-9a79-fb2701da70ff"
      },
      "source": [
        "# Set strategy choice\n",
        "USE_GPU = True\n",
        "USE_CPU = False\n",
        "\n",
        "# Set strategy with config. Our code should run on all.\n",
        "if USE_GPU:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device = \"/gpu:0\")\n",
        "if USE_CPU:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device = \"/cpu:0\")\n",
        "\n",
        "# Constants\n",
        "MAX_LEN = 512\n",
        "EPOCHS = 2\n",
        "VERBOSE = 1  \n",
        "\n",
        "# Batch Size\n",
        "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
        "print(f'Batch Size: {BATCH_SIZE}')\n",
        "\n",
        "# Learning Rate\n",
        "LR = 1e-6 * strategy.num_replicas_in_sync\n",
        "print('Learning Rate: {}'.format(LR))\n",
        "\n",
        "# Set RoBERTa Type\n",
        "roberta_type = 'roberta-base'\n",
        "print(f'RoBERTa Model Type: {roberta_type}')\n",
        "\n",
        "# Set RoBERTa Config\n",
        "roberta_config = RobertaConfig.from_pretrained(roberta_type, num_labels = 2) # Binary classification so set num_labels = 2\n",
        "\n",
        "# Set RoBERTa Tokenizer\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(roberta_type, \n",
        "                                                     return_dict = True,\n",
        "                                                     add_prefix_space = True,\n",
        "                                                     do_lower_case = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Size: 8\n",
            "Learning Rate: 1e-06\n",
            "RoBERTa Model Type: roberta-base\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svf9DNnerOGQ"
      },
      "source": [
        "Next we define a function to process the 't5_generated_fake_news.csv' which is loaded as a Pandas Dataframe. We loop through all rows and from each row we use the columns 'description' and 'generated' as input for the RoBERTa model.\n",
        "\n",
        "The 'description' input will be labelled with 0. The 'generated' input will be labelled with 1. The 'title' which we used in the T5 model is not used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRYegA4up8rn"
      },
      "source": [
        "def create_dataset(df):\n",
        "    number_of_samples = df.shape[0]\n",
        "    total_samples = 2 * df.shape[0]\n",
        "\n",
        "    # Placeholders input\n",
        "    input_ids = np.zeros((total_samples, MAX_LEN), dtype = 'int32')\n",
        "    input_masks = np.zeros((total_samples, MAX_LEN), dtype = 'int32')\n",
        "    labels = np.zeros((total_samples, ), dtype = 'int32')\n",
        "\n",
        "    for index, row in tqdm(zip(range(0, total_samples, 2), train_df.iterrows()), total = number_of_samples):\n",
        "        \n",
        "        # Get title and description as strings\n",
        "        description = row[1]['description']\n",
        "        generated = row[1]['generated']\n",
        "\n",
        "        # Process Description - Set Label for real as 0\n",
        "        input_encoded = roberta_tokenizer.encode_plus(description, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "        input_ids_sample = input_encoded['input_ids']\n",
        "        input_ids[index,:len(input_ids_sample)] = input_ids_sample\n",
        "        attention_mask_sample = input_encoded['attention_mask']\n",
        "        input_masks[index,:len(attention_mask_sample)] = attention_mask_sample\n",
        "        labels[index] = 0\n",
        "\n",
        "        # Process Generated - Set Label for fake as 1\n",
        "        input_encoded = roberta_tokenizer.encode_plus(generated, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "        input_ids_sample = input_encoded['input_ids']\n",
        "        input_ids[index+1,:len(input_ids_sample)] = input_ids_sample\n",
        "        attention_mask_sample = input_encoded['attention_mask']\n",
        "        input_masks[index+1,:len(attention_mask_sample)] = attention_mask_sample\n",
        "        labels[index+1] = 1\n",
        "\n",
        "    # Create DatasetDictionary structure is also preserved.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': input_ids, 'attention_mask': input_masks}, labels))\n",
        "\n",
        "    # Return Dataset\n",
        "    return dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnDg0qvIscGa"
      },
      "source": [
        "We load the csv file. Split it into an 80/20 train and test set and call the previously defined function to generate our final Tensorflow Datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drBI9oUaDNxG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187,
          "referenced_widgets": [
            "042381bac88044ddb377384a23c45d9f",
            "e9975b699b304dcf86da83269d80821a",
            "014e8adcb70045549f5dd953b690ef4e",
            "25d0f27580784cf999ba635a058fd9d3",
            "576de57bd46d4a87bfc939ee1bd2cd8b",
            "f5e6f118ac834b1daa9f96a54dc07bc2",
            "610c88b795ea4e139f59ec7ace281e73",
            "831f7bf0a15d474b90aec3f2ee8c0503",
            "f5cb099e47fd463baa3eba394fb2f20e",
            "bf0f2e2fd39f4114b1c8fda85311a515",
            "a7c13c71184541f48972ae1bdd00f45d",
            "7c026b8f0a6145c7be1db6999674cb4a",
            "73bdb7cbf5314656b4b361902e416727",
            "ca272e5ee2464b72a0645e5d21417611",
            "8b06ab290d4940539cb0a46e3c07b721",
            "153b0d34898542659b56a418f97cdb88"
          ]
        },
        "outputId": "3b40d6c3-3d8d-42d1-b3a5-76c3d24f5758"
      },
      "source": [
        "# Import Generated Fake News\n",
        "df = pd.read_csv(WORK_DIR + 't5_generated_fake_news.csv')\n",
        "\n",
        "# Split in Train and Validation\n",
        "train_df, val_df = train_test_split(df, test_size = 0.2, random_state = 42, shuffle = True)\n",
        "\n",
        "# Show Sizes\n",
        "print(f'Train Shape: {train_df.shape}')\n",
        "print(f'Validation Shape: {val_df.shape}')\n",
        "\n",
        "# Create Train Dataset\n",
        "train_dataset = create_dataset(train_df)\n",
        "train_dataset = train_dataset.shuffle(2048)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.repeat(-1)\n",
        "train_dataset = train_dataset.prefetch(128)\n",
        "\n",
        "# Create Validation Dataset\n",
        "validation_dataset = create_dataset(val_df)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE)\n",
        "validation_dataset = validation_dataset.repeat(-1)\n",
        "validation_dataset = validation_dataset.prefetch(128)\n",
        "\n",
        "# Steps\n",
        "train_steps = (train_df.shape[0] * 2) // BATCH_SIZE\n",
        "val_steps = (val_df.shape[0] * 2) // BATCH_SIZE\n",
        "print(f'Train Steps: {train_steps}')\n",
        "print(f'Val Steps: {val_steps}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Shape: (48000, 4)\n",
            "Validation Shape: (12000, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "042381bac88044ddb377384a23c45d9f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=48000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5cb099e47fd463baa3eba394fb2f20e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=12000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Steps: 12000\n",
            "Val Steps: 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWhqdE2vucKu"
      },
      "source": [
        "Define a function to create and compile the RoBERTa base model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WmEQKkVSkzZ"
      },
      "source": [
        "def create_model():\n",
        "    # Create Model\n",
        "    with strategy.scope():      \n",
        "        model = TFRobertaForSequenceClassification.from_pretrained(roberta_type, config = roberta_config)\n",
        "        \n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate = LR)\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "        model.compile(optimizer = optimizer, loss = loss, metrics = [metric])        \n",
        "        \n",
        "        return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfdvlzpLuvH9"
      },
      "source": [
        "Create a callback to save the model weights to storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TIeTbjMcmKV"
      },
      "source": [
        "class SaveModel(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs = None):\n",
        "        print(\"\\nSave Model Weights\")\n",
        "\n",
        "        # Save the entire model as a SavedModel.\n",
        "        self.model.save_weights(WORK_DIR + 'roberta_base_model.h5')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdC2LfpHu2Cq"
      },
      "source": [
        "Finally create the model and perform the training and validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpndxxesSwq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90def64f-508b-4d41-8c01-68bbab85faa2"
      },
      "source": [
        "  # Create Model\n",
        "  model = create_model()\n",
        "\n",
        "  # Summary\n",
        "  model.summary()\n",
        "\n",
        "  # Fit Model\n",
        "  model.fit(train_dataset,\n",
        "            steps_per_epoch = train_steps,\n",
        "            validation_data = validation_dataset,\n",
        "            validation_steps = val_steps,\n",
        "            epochs = EPOCHS, \n",
        "            verbose = VERBOSE,\n",
        "            callbacks = [SaveModel()])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaForSequenceClassification: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_roberta_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "roberta (TFRobertaMainLayer) multiple                  124645632 \n",
            "_________________________________________________________________\n",
            "classifier (TFRobertaClassif multiple                  592130    \n",
            "=================================================================\n",
            "Total params: 125,237,762\n",
            "Trainable params: 125,237,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "12000/12000 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9389\n",
            "Save Model Weights\n",
            "12000/12000 [==============================] - 4317s 360ms/step - loss: 0.1371 - accuracy: 0.9389 - val_loss: 0.0941 - val_accuracy: 0.9635\n",
            "Epoch 2/2\n",
            "12000/12000 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9846\n",
            "Save Model Weights\n",
            "12000/12000 [==============================] - 4315s 360ms/step - loss: 0.0423 - accuracy: 0.9846 - val_loss: 0.0517 - val_accuracy: 0.9805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9db2d18b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwlD15Ytvb3N"
      },
      "source": [
        "After training the model should achieve around 97% accuracy on the validation set.\n",
        "\n",
        "And interresting point I noticed during testing is that the 97% accuracy was achieved based on the fake news as generated by a trained T5-base model.\n",
        "\n",
        "When I performed the initial tests with fake news generated by a trained T5-small model the classifier could achieve around 99% accuracy. This makes sense as you would expect a smaller NLP model to be able to generate less 'natural looking' fake news. The 97% classification accuracy achieved on the fake news generated by the T5-base model more or less proves that it generates better fake news."
      ]
    }
  ]
}