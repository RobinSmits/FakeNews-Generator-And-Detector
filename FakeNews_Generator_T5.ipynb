{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNews_Generator_T5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNY/adbfzHxTEBy6WEUwtbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f52acccd6cba4dde9d5ecfb4d04b6e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9a04f2b296845a88248d1570d18c70a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_96e794e6721742729588563243b12abd",
              "IPY_MODEL_55693ea6dab84ae797dad40bc624c116"
            ]
          }
        },
        "b9a04f2b296845a88248d1570d18c70a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96e794e6721742729588563243b12abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff892aa7b2134ec389fe4f6698225b87",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 60000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 60000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_990103e66f274ffca62293ec08278600"
          }
        },
        "55693ea6dab84ae797dad40bc624c116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2796b2cd7e4d43e0bb0d40e82dd5cb21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60000/60000 [01:38&lt;00:00, 608.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54af59bf09804230ba70c662aed6e26e"
          }
        },
        "ff892aa7b2134ec389fe4f6698225b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "990103e66f274ffca62293ec08278600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2796b2cd7e4d43e0bb0d40e82dd5cb21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54af59bf09804230ba70c662aed6e26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd8a092e60bc4af7a497f8140f51ba90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1ab7e046369a430295007194c8eb35e6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0fb938a1248c4b1984dcd716462b4ecb",
              "IPY_MODEL_cd0ef41498c441188268cc6c581046bf"
            ]
          }
        },
        "1ab7e046369a430295007194c8eb35e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fb938a1248c4b1984dcd716462b4ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_77a31c1ca9a94163822a94e7bc12393d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 892146080,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 892146080,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32b8c744e4fb4e94b3f453c6dafbb428"
          }
        },
        "cd0ef41498c441188268cc6c581046bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f420eb8245344465967fe0d7537c41b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:25&lt;00:00, 35.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e53ce24c1af45749221da39ccfaf497"
          }
        },
        "77a31c1ca9a94163822a94e7bc12393d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32b8c744e4fb4e94b3f453c6dafbb428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f420eb8245344465967fe0d7537c41b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e53ce24c1af45749221da39ccfaf497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85ac0d16369646a4bc63007c9c668e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55334345040a4d3187f494371d825819",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d66c99d7c46e4565b590cfde20e2ff7f",
              "IPY_MODEL_3f7bfdb7c61444fba6e6e8dd371146ec"
            ]
          }
        },
        "55334345040a4d3187f494371d825819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d66c99d7c46e4565b590cfde20e2ff7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_37ef08c754cf49e3846ed4fd02961a33",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 60000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 60000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d10dc25a4d6b476489f1c069fd962b8c"
          }
        },
        "3f7bfdb7c61444fba6e6e8dd371146ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3252f1dbafa4b7aa71afd5603824590",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60000/60000 [00:14&lt;00:00, 4250.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ef26ecd2da441bb98dbd2aeedbf50ff"
          }
        },
        "37ef08c754cf49e3846ed4fd02961a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d10dc25a4d6b476489f1c069fd962b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3252f1dbafa4b7aa71afd5603824590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ef26ecd2da441bb98dbd2aeedbf50ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4a3c010c1994448877c35e46acc5e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3cce92d408d14a13a12ef3f4b4772685",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8754f9e335044e02886d239c7dc32fed",
              "IPY_MODEL_808f4f4328d548fbb9652836efcd74d6"
            ]
          }
        },
        "3cce92d408d14a13a12ef3f4b4772685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8754f9e335044e02886d239c7dc32fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9c658d717dc45c38665a77b573821d8",
            "_dom_classes": [],
            "description": " 19%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 60000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11160,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be9aa0a4dcac403db00cc87c878291db"
          }
        },
        "808f4f4328d548fbb9652836efcd74d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df748b53e73d4f90b18ef20bb701c25b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11160/60000 [3:16:22&lt;6:09:03,  2.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12973eb45b7b4a2b8f75998395b46fda"
          }
        },
        "d9c658d717dc45c38665a77b573821d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be9aa0a4dcac403db00cc87c878291db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df748b53e73d4f90b18ef20bb701c25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12973eb45b7b4a2b8f75998395b46fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobinSmits/FakeNews-Generator-And-Detector/blob/main/FakeNews_Generator_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFLz1oijbeuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3565514d-c3a1-4540-dec9-cde951249336"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "!pip install transformers==3.5.1\n",
        "from transformers import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.5.1 in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (3.0.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (0.7)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (0.9.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.1) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5.1) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeMRy7d8kKul"
      },
      "source": [
        "I've created and tested these notebooks on Google Colab Pro and used Google Drive to store and load any files created. \n",
        "\n",
        "If you run the code locally on a computer then modify the 'WORK_DIR' accordingly. Google Drive will not be needed in that case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RjCDJ7YzUdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c351850-8655-4eb6-b526-98908ac33843"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set Folder to use...\n",
        "WORK_DIR = '/content/drive/My Drive/fake_news'\n",
        "os.makedirs(WORK_DIR, exist_ok = True) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBdz1gKalwCo"
      },
      "source": [
        "Next we set some config for the device to use (Note: TPU to be added/tested in the future.) Next we set some constants. For the learning rate you could try different settings. If the model generates only garbage...then likely the learning rate was set to high.\n",
        "\n",
        "You can set 2 actions:\n",
        "\n",
        "1.   PERFORM_TRAINING: Set to True to Train a T5 Model from scratch.\n",
        "2.   GENERATE_TEXT: Set to True to use a T5 Model to generate a text file with fake news. Note that generation can take a long time (multiple hours)\n",
        "\n",
        "And finally we set the T5 tokenizer and config to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7jUGKre059v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad37351-a30e-4ce6-9971-78b697097ffc"
      },
      "source": [
        "# Set Device to Run on.\n",
        "USE_GPU = True\n",
        "USE_CPU = False\n",
        "\n",
        "# Set strategy with config\n",
        "if USE_GPU:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device = \"/gpu:0\")\n",
        "if USE_CPU:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device = \"/cpu:0\")\n",
        "\n",
        "# TODO: Add and test TPU functioning\n",
        "\n",
        "# Constants\n",
        "MAX_LEN = 512     # Max number of tokens for T5 to use.\n",
        "EPOCHS = 1\n",
        "VERBOSE = 1\n",
        "TRAIN_SPLITS = 2\n",
        "\n",
        "# Set Actions\n",
        "PERFORM_TRAINING = True\n",
        "GENERATE_TEXT = True\n",
        "\n",
        "# Batch Size\n",
        "GENERATE_BATCH_SIZE = 30 * strategy.num_replicas_in_sync\n",
        "BATCH_SIZE = 4 * strategy.num_replicas_in_sync\n",
        "print(f'Train Batch Size: {BATCH_SIZE}')\n",
        "print(f'Generate Batch Size: {GENERATE_BATCH_SIZE}')\n",
        "\n",
        "# Learning Rate\n",
        "LR = 1e-4 * strategy.num_replicas_in_sync\n",
        "print('Learning Rate: {}'.format(LR))\n",
        "\n",
        "# Set T5 Type\n",
        "t5_size = 't5-base'     \n",
        "print(f'T5 Model Type: {t5_size}')\n",
        "\n",
        "# Set T5 Task Name\n",
        "task_name = 'generate fake news: '\n",
        "print(f'T5 Task Name: {task_name}')\n",
        "\n",
        "# Set T5 Config\n",
        "t5_config = T5Config.from_pretrained(t5_size)\n",
        "\n",
        "# Set T5 Tokenizer\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(t5_size, return_dict = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Batch Size: 4\n",
            "Generate Batch Size: 30\n",
            "Learning Rate: 0.0001\n",
            "T5 Model Type: t5-base\n",
            "T5 Task Name: generate fake news: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2Qu820inewG"
      },
      "source": [
        "For Training and Generation we will use the Tensorflow Dataset 'ag_news_subset'. It contains a train set of 120K rows and a test set of 7600 rows.\n",
        "\n",
        "Each row contains a 'title' which is a news paper headline and a 'description' which is a short part of the news paper article.\n",
        "\n",
        "The 'title' will be used as input and the long text 'description' will be specified as output. This way we can train the model to generate 'fake news' based on a short input.\n",
        "\n",
        "We will split the train set in to 2 equal parts each with 60K rows.\n",
        "\n",
        "The first set will be used to train the T5 model on its task.\n",
        "The second set will be used to generate new data (the fake news...) with input data that the T5 model has never seen before.\n",
        "\n",
        "!! Note: I've experienced multiple times that on the initial download of the dataset an error occurs. If you run it again it will just work..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw1Xoc0GeFYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe38854-5fd1-478a-8b8a-f121b396d65a"
      },
      "source": [
        "# Define Splits\n",
        "splits = tfds.even_splits('train', n = TRAIN_SPLITS)\n",
        "print(f'Configured Splits: {splits}')\n",
        "\n",
        "# Get data and datasets\n",
        "ag_news_ds, info = tfds.load('ag_news_subset', split = splits, with_info = True, shuffle_files = True, as_supervised = False)\n",
        "train_ds = ag_news_ds[0]\n",
        "generate_ds = ag_news_ds[1]\n",
        "\n",
        "# Dataset features\n",
        "print(f'Show Dataset Features:\\n {info.features}')\n",
        "\n",
        "# Samples\n",
        "total_train_samples = int(info.splits['train'].num_examples / TRAIN_SPLITS) \n",
        "total_generate_samples = int(info.splits['train'].num_examples / TRAIN_SPLITS) \n",
        "\n",
        "# Summary\n",
        "print(f'Total Samples for Training: {total_train_samples}')\n",
        "print(f'Total Samples for Generation: {total_generate_samples}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/ag_news_subset/1.0.0\n",
            "INFO:absl:Reusing dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split ['train[0%:50%]', 'train[50%:100%]'], from /root/tensorflow_datasets/ag_news_subset/1.0.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Configured Splits: ['train[0%:50%]', 'train[50%:100%]']\n",
            "Show Dataset Features:\n",
            " FeaturesDict({\n",
            "    'description': Text(shape=(), dtype=tf.string),\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
            "    'title': Text(shape=(), dtype=tf.string),\n",
            "})\n",
            "Total Samples for Training: 60000\n",
            "Total Samples for Generation: 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqBtjG0ApjZf"
      },
      "source": [
        "Next map the train_ds and generate_ds to use only the 'description' and 'title'. The train_ds is used for training the model. The generate_ds is used for generating the fake news."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mhpLXSKCOrK"
      },
      "source": [
        "# Map and Decode Split(s)\n",
        "def decode_example(example):\n",
        "    decoded_example = info.features.decode_example(example)\n",
        "    \n",
        "    description = decoded_example['description']\n",
        "    title = decoded_example['title']\n",
        "    \n",
        "    return title, description\n",
        "\n",
        "# Map\n",
        "train_ds = train_ds.map(decode_example, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "generate_ds = generate_ds.map(decode_example, num_parallel_calls = tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evMtmdIepxtE"
      },
      "source": [
        "Lets look at some tokenized samples from the train_ds and generate_ds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eure1ID0Hhx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bcedbd-3d0f-4e66-c140-a20e99e0ca44"
      },
      "source": [
        "# Train: Show Input and Output Samples encoded\n",
        "train_ds_numpy = tfds.as_numpy(train_ds.take(2))\n",
        "\n",
        "for sample in train_ds_numpy:\n",
        "    # Get title and description as strings\n",
        "    title = sample[0].decode('utf-8')\n",
        "    description = sample[1].decode('utf-8')\n",
        "    \n",
        "    # Encode with special tokens and use maximum length\n",
        "    input_encoded = t5_tokenizer.encode_plus(title, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "    output_encoded = t5_tokenizer.encode_plus(description, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "    \n",
        "    # Print...\n",
        "    print(f'Title: {title}')\n",
        "    print(f'Input - Title Encoded: {input_encoded}')\n",
        "    print(f'Description: {description}')\n",
        "    print(f'Output - Description Encoded: {output_encoded}\\n')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title: AMD Debuts Dual-Core Opteron Processor\n",
            "Input - Title Encoded: {'input_ids': [22806, 374, 2780, 7, 17338, 18, 13026, 15, 4495, 449, 106, 10272, 127, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Description: AMD #39;s new dual-core Opteron chip is designed mainly for corporate computing applications, including databases, Web services, and financial transactions.\n",
            "Output - Description Encoded: {'input_ids': [22806, 1713, 3288, 117, 7, 126, 7013, 18, 9022, 4495, 449, 106, 6591, 19, 876, 3, 4894, 21, 2849, 10937, 1564, 6, 379, 16961, 6, 1620, 364, 6, 11, 981, 6413, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "Title: Wood's Suspension Upheld (Reuters)\n",
            "Input - Title Encoded: {'input_ids': [2985, 31, 7, 1923, 7, 3208, 1938, 3234, 14796, 41, 18844, 61, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Description: Reuters - Major League Baseball\\Monday announced a decision on the appeal filed by Chicago Cubs\\pitcher Kerry Wood regarding a suspension stemming from an\\incident earlier this season.\n",
            "Output - Description Encoded: {'input_ids': [3, 18844, 3, 18, 9236, 3815, 22398, 2, 9168, 1135, 2162, 3, 9, 1357, 30, 8, 3958, 5132, 57, 3715, 18640, 7, 2, 5230, 1703, 24967, 2985, 1918, 3, 9, 9756, 6269, 51, 53, 45, 46, 2, 77, 75, 4215, 2283, 48, 774, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KKtyEtbQG1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a298435-861b-4e7e-8e38-07f8a129191a"
      },
      "source": [
        "# Test: Show Input and Output Samples encoded\n",
        "generate_ds_numpy = tfds.as_numpy(generate_ds.take(2))\n",
        "\n",
        "for batch in generate_ds_numpy:\n",
        "    # Get title and description as strings\n",
        "    title = batch[0].decode('utf-8')\n",
        "    description = batch[1].decode('utf-8')\n",
        "    \n",
        "    # Encode with special tokens and use maximum length\n",
        "    input_encoded = t5_tokenizer.encode_plus(title, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "    output_encoded = t5_tokenizer.encode_plus(description, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "            \n",
        "    # Print...\n",
        "    print(f'Title: {title}')\n",
        "    print(f'Input - Title Encoded: {input_encoded}')\n",
        "    print(f'Description: {description}')\n",
        "    print(f'Output - Description Encoded: {output_encoded}\\n')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title: XM Strikes Back\n",
            "Input - Title Encoded: {'input_ids': [3, 4, 329, 5500, 5208, 7, 3195, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Description: Two weeks after its rival Sirius Satellite Radio (Nasdaq: SIRI) grabbed headlines by signing Howard Stern, XM Satellite Radio (Nasdaq: XMSR) disclosed late yesterday that it \n",
            "Output - Description Encoded: {'input_ids': [2759, 1274, 227, 165, 8374, 22438, 302, 24552, 5061, 41, 567, 9, 7, 26, 9, 1824, 10, 7933, 5593, 61, 19303, 26, 12392, 7, 57, 8097, 13816, 17594, 6, 3, 4, 329, 24552, 5061, 41, 567, 9, 7, 26, 9, 1824, 10, 3, 4, 4211, 448, 61, 19972, 1480, 4981, 24, 34, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "Title: RIGHT GAINS IN LITHUANIA ELECTIONS\n",
            "Input - Title Encoded: {'input_ids': [3, 27262, 10615, 14750, 3388, 8729, 4611, 16597, 26077, 3, 3577, 14196, 22164, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Description: Right-wing parties have scored a surprise success in Lithuania #39;s parliamentary elections on the weekend. The right-wing Conservative Party and Liberal Center Union party won 43 seats together in the 141-member parliament.\n",
            "Output - Description Encoded: {'input_ids': [5068, 18, 3108, 2251, 43, 5799, 3, 9, 4158, 1269, 16, 27620, 1713, 3288, 117, 7, 3, 28443, 9768, 30, 8, 1851, 5, 37, 269, 18, 3108, 23053, 3450, 11, 18587, 1166, 3545, 1088, 751, 8838, 6116, 544, 16, 8, 3, 26059, 18, 12066, 20417, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ5jgmnsqRFf"
      },
      "source": [
        "Perform processing of the train_ds and prepare the data for model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drBI9oUaDNxG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "f52acccd6cba4dde9d5ecfb4d04b6e89",
            "b9a04f2b296845a88248d1570d18c70a",
            "96e794e6721742729588563243b12abd",
            "55693ea6dab84ae797dad40bc624c116",
            "ff892aa7b2134ec389fe4f6698225b87",
            "990103e66f274ffca62293ec08278600",
            "2796b2cd7e4d43e0bb0d40e82dd5cb21",
            "54af59bf09804230ba70c662aed6e26e"
          ]
        },
        "outputId": "63f95ee3-397f-4fe0-bbe4-4d460d4e3dd3"
      },
      "source": [
        "# Placeholders input\n",
        "input_ids = np.zeros((total_train_samples, MAX_LEN), dtype='int32')\n",
        "input_masks = np.zeros((total_train_samples, MAX_LEN), dtype='int32')\n",
        "\n",
        "# Placeholders output\n",
        "output_ids = np.zeros((total_train_samples, MAX_LEN), dtype='int32')\n",
        "output_masks = np.zeros((total_train_samples, MAX_LEN), dtype='int32')\n",
        "\n",
        "# Process Tensorflow Dataset as Numpy ... otherwise not possible to process tokenization.\n",
        "train_ds_numpy = tfds.as_numpy(train_ds)\n",
        "\n",
        "for index, sample in tqdm(zip(range(total_train_samples), train_ds_numpy), total = total_train_samples):\n",
        "    \n",
        "    # Get title and description as strings\n",
        "    title = sample[0].decode('utf-8')\n",
        "    description = sample[1].decode('utf-8')\n",
        "    \n",
        "    # Process Input\n",
        "    input_encoded = t5_tokenizer.encode_plus(task_name + title, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "    input_ids_sample = input_encoded['input_ids']\n",
        "    input_ids[index,:len(input_ids_sample)] = input_ids_sample\n",
        "    attention_mask_sample = input_encoded['attention_mask']\n",
        "    input_masks[index,:len(attention_mask_sample)] = attention_mask_sample\n",
        "\n",
        "    # Process Output\n",
        "    output_encoded = t5_tokenizer.encode_plus(description, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "    output_ids_sample = output_encoded['input_ids']\n",
        "    output_ids[index,:len(output_ids_sample)] = output_ids_sample\n",
        "    attention_mask_sample = output_encoded['attention_mask']\n",
        "    output_masks[index,:len(attention_mask_sample)] = attention_mask_sample"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f52acccd6cba4dde9d5ecfb4d04b6e89",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUwZxYCqqhUu"
      },
      "source": [
        "Create the Keras Model to be used for T5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WmEQKkVSkzZ"
      },
      "source": [
        "class KerasTFT5ForConditionalGeneration(TFT5ForConditionalGeneration):\n",
        "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n",
        "    \n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        x = data[0]\n",
        "        y = x['labels']\n",
        "        y = tf.reshape(y, [-1, 1])\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = self(x, training=True)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            loss = tf.reduce_mean(loss)\n",
        "            grads = tape.gradient(loss, self.trainable_variables)\n",
        "            \n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "        self.loss_tracker.update_state(loss)        \n",
        "        self.compiled_metrics.update_state(y, logits)\n",
        "        metrics = {m.name: m.result() for m in self.metrics}\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x = data[0]\n",
        "        y = x[\"labels\"]\n",
        "        y = tf.reshape(y, [-1, 1])\n",
        "        output = self(x, training=False)\n",
        "        loss = output[0]\n",
        "        loss = tf.reduce_mean(loss)\n",
        "        logits = output[1]\n",
        "        \n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.compiled_metrics.update_state(y, logits)\n",
        "        \n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoRxLwhfqq4n"
      },
      "source": [
        "Create a callback to save the model weights to storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TIeTbjMcmKV"
      },
      "source": [
        "class SaveModel(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs = None):\n",
        "        print(\"\\nSave Model Weights\")\n",
        "\n",
        "        # Save the entire model as a SavedModel.\n",
        "        self.model.save_weights(WORK_DIR + 't5_base_model.h5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TX7ns2Rq3xV"
      },
      "source": [
        "Finally create and compile the model. Show the summary. Set the final input_data and perform the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpndxxesSwq5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531,
          "referenced_widgets": [
            "bd8a092e60bc4af7a497f8140f51ba90",
            "1ab7e046369a430295007194c8eb35e6",
            "0fb938a1248c4b1984dcd716462b4ecb",
            "cd0ef41498c441188268cc6c581046bf",
            "77a31c1ca9a94163822a94e7bc12393d",
            "32b8c744e4fb4e94b3f453c6dafbb428",
            "f420eb8245344465967fe0d7537c41b7",
            "6e53ce24c1af45749221da39ccfaf497"
          ]
        },
        "outputId": "9085408f-f0bf-470b-9f80-325c78b2a547"
      },
      "source": [
        "# Perform training only if specified\n",
        "if PERFORM_TRAINING:\n",
        "        \n",
        "    # Create Model\n",
        "    with strategy.scope():\n",
        "        model = KerasTFT5ForConditionalGeneration.from_pretrained(t5_size, config = t5_config)\n",
        "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = LR), \n",
        "                      metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name = 'accuracy')])\n",
        "\n",
        "    # Summary\n",
        "    model.summary()\n",
        "\n",
        "    # Set Input\n",
        "    input_data = {'input_ids': input_ids, 'labels': output_ids, 'attention_mask': input_masks, 'decoder_attention_mask': output_masks}\n",
        "\n",
        "    # Fit Model\n",
        "    model.fit(input_data,\n",
        "              epochs = EPOCHS, \n",
        "              batch_size = BATCH_SIZE, \n",
        "              verbose = VERBOSE,\n",
        "              shuffle = True,\n",
        "              callbacks = [SaveModel()],\n",
        "              use_multiprocessing = False,\n",
        "              workers = 4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd8a092e60bc4af7a497f8140f51ba90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=892146080.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing KerasTFT5ForConditionalGeneration.\n",
            "\n",
            "Some layers of KerasTFT5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['loss']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"keras_tf_t5for_conditional_generation\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "shared (TFSharedEmbeddings)  multiple                  24674304  \n",
            "_________________________________________________________________\n",
            "encoder (TFT5MainLayer)      multiple                  84954240  \n",
            "_________________________________________________________________\n",
            "decoder (TFT5MainLayer)      multiple                  113275392 \n",
            "_________________________________________________________________\n",
            "loss (Mean)                  multiple                  2         \n",
            "=================================================================\n",
            "Total params: 222,903,938\n",
            "Trainable params: 222,903,936\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - ETA: 0s - accuracy: 0.9680 - loss: 0.2779\n",
            "Save Model Weights\n",
            "15000/15000 [==============================] - 10434s 696ms/step - accuracy: 0.9680 - loss: 0.2779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z40n7bAgrt_y"
      },
      "source": [
        "If GENERATE_TEXT is true than create the model and load the weights file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QF29NXqRUkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37b11f9-1977-4eaa-82f0-c56979e777a7"
      },
      "source": [
        "if GENERATE_TEXT:        \n",
        "    # Create Model\n",
        "    with strategy.scope():\n",
        "        model = KerasTFT5ForConditionalGeneration.from_pretrained(t5_size, config = t5_config)\n",
        "        model.compile(optimizer = tf.keras.optimizers.Adam(), \n",
        "                      metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name = 'accuracy')])\n",
        "\n",
        "    # Summary\n",
        "    model.summary()\n",
        "\n",
        "    # Load Weights\n",
        "    model.load_weights(WORK_DIR + 't5_base_model.h5')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing KerasTFT5ForConditionalGeneration.\n",
            "\n",
            "Some layers of KerasTFT5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['loss']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"keras_tf_t5for_conditional_generation_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "shared (TFSharedEmbeddings)  multiple                  24674304  \n",
            "_________________________________________________________________\n",
            "encoder (TFT5MainLayer)      multiple                  84954240  \n",
            "_________________________________________________________________\n",
            "decoder (TFT5MainLayer)      multiple                  113275392 \n",
            "_________________________________________________________________\n",
            "loss (Mean)                  multiple                  2         \n",
            "=================================================================\n",
            "Total params: 222,903,938\n",
            "Trainable params: 222,903,936\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF2QLSrcsLTO"
      },
      "source": [
        "Lets show a few examples of the generated fake news. The 'title' is shown as is the original 'description'. The 'Generated Fake News' is the output generated by the T5 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBjsnICLS2BG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fbe0549-2c86-447d-d82b-413731fc96c2"
      },
      "source": [
        "if GENERATE_TEXT:\n",
        "    # Test: Show Input and Output Samples encoded\n",
        "    generate_samples = 4\n",
        "    generate_ds_numpy = tfds.as_numpy(generate_ds.take(generate_samples))\n",
        "\n",
        "    for index, sample in zip(range(generate_samples), generate_ds_numpy):\n",
        "        # Get title and description as strings\n",
        "        title = sample[0].decode('utf-8')\n",
        "        description = sample[1].decode('utf-8')\n",
        "\n",
        "        print(f'\\n\\n========= Sample:  {index}')\n",
        "        print(f'Title: {title}')\n",
        "        print(f'Description: {description}')\n",
        "\n",
        "        # Encode with Special Tokens\n",
        "        input_encoded = t5_tokenizer.encode_plus(task_name + title, add_special_tokens = True, max_length = MAX_LEN, padding = True, truncation = True, return_tensors = 'tf')\n",
        "        \n",
        "        # Generate FakeNews\n",
        "        generated_fakenews = model.generate(input_encoded['input_ids'], \n",
        "                                          attention_mask = input_encoded['attention_mask'], \n",
        "                                          max_length = MAX_LEN, \n",
        "                                          top_p = 0.95, \n",
        "                                          top_k = 256, \n",
        "                                          temperature = 1.1,\n",
        "                                          num_beams = 1, \n",
        "                                          num_return_sequences = 1, \n",
        "                                          repetition_penalty = 1.1)\n",
        "\n",
        "        for mapping in generated_fakenews.numpy():\n",
        "            decoded_mapping = t5_tokenizer.decode(mapping)\n",
        "            print(f\"    Generated Fake News: {decoded_mapping}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "========= Sample:  0\n",
            "Title: XM Strikes Back\n",
            "Description: Two weeks after its rival Sirius Satellite Radio (Nasdaq: SIRI) grabbed headlines by signing Howard Stern, XM Satellite Radio (Nasdaq: XMSR) disclosed late yesterday that it \n",
            "    Generated Fake News: XM Satellite Radio is back in the news, but it #39;s not the only one that has been a hit.\n",
            "\n",
            "\n",
            "========= Sample:  1\n",
            "Title: RIGHT GAINS IN LITHUANIA ELECTIONS\n",
            "Description: Right-wing parties have scored a surprise success in Lithuania #39;s parliamentary elections on the weekend. The right-wing Conservative Party and Liberal Center Union party won 43 seats together in the 141-member parliament.\n",
            "    Generated Fake News: ATHENS (Reuters) - The right hander of the right hander of the left hander of the left hander of the left hander of the left hander of the left hander of the left hander of the left hander of the left hander of the left hander of the left hander of the left hander, sat in the middle of the room and sat in the middle of the room.\n",
            "\n",
            "\n",
            "========= Sample:  2\n",
            "Title: Spain sweeps opening singles from US in Davis Cup final\n",
            "Description: With drums pounding and a brass band playing, Andy Roddick and his US teammates were reduced to silence yesterday in the Davis Cup final.\n",
            "    Generated Fake News: Spain beat the US 6-4, 6-2 in the first round of the Davis Cup final on Friday. The Spaniards won their first singles match since the beginning of the season.\n",
            "\n",
            "\n",
            "========= Sample:  3\n",
            "Title: Before the Bell: GE, Sirius Slip (Reuters)\n",
            "Description: Reuters - Shares of General Electric Co. \\fell slightly before the bell on Friday after the industrial\\conglomerate said quarterly earnings rose.\n",
            "    Generated Fake News: Reuters - Shares of ⁇ GE and Sirius ⁇ Sirius fell on ⁇ Friday after the companies ⁇ said they had ⁇ sold out on ⁇ the ⁇ biggest ⁇ sales in ⁇ a decade.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyY_B5AVsCI9"
      },
      "source": [
        "Use the generate_ds to prepare the final dataframe that will be saved to disk after the fake news generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "85ac0d16369646a4bc63007c9c668e64",
            "55334345040a4d3187f494371d825819",
            "d66c99d7c46e4565b590cfde20e2ff7f",
            "3f7bfdb7c61444fba6e6e8dd371146ec",
            "37ef08c754cf49e3846ed4fd02961a33",
            "d10dc25a4d6b476489f1c069fd962b8c",
            "c3252f1dbafa4b7aa71afd5603824590",
            "1ef26ecd2da441bb98dbd2aeedbf50ff"
          ]
        },
        "id": "pyB3HpSPnAEP",
        "outputId": "5c75776d-f2eb-4b85-a9c0-bbeefce59b0e"
      },
      "source": [
        "if GENERATE_TEXT:\n",
        "    # Placeholders\n",
        "    titles, descriptions = [], []\n",
        "    \n",
        "    # Process Tensorflow Dataset as Numpy ... otherwise not possible to process tokenization.\n",
        "    generate_ds_numpy = tfds.as_numpy(generate_ds)\n",
        "\n",
        "    for index, sample in tqdm(zip(range(total_generate_samples), generate_ds_numpy), total = total_generate_samples):\n",
        "        # Get title and description as strings\n",
        "        titles.append(sample[0].decode('utf-8'))             # title\n",
        "        descriptions.append(sample[1].decode('utf-8'))       # description = \n",
        "\n",
        "    # Create Dataframe\n",
        "    df = pd.DataFrame()\n",
        "    df['title'] = titles\n",
        "    df['description'] = descriptions\n",
        "    df['generated'] = ''\n",
        "\n",
        "    # Summary\n",
        "    print(df.head())\n",
        "    print(df.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85ac0d16369646a4bc63007c9c668e64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                                               title  ... generated\n",
            "0                                    XM Strikes Back  ...          \n",
            "1                 RIGHT GAINS IN LITHUANIA ELECTIONS  ...          \n",
            "2  Spain sweeps opening singles from US in Davis ...  ...          \n",
            "3         Before the Bell: GE, Sirius Slip (Reuters)  ...          \n",
            "4                  Microsoft takes on desktop search  ...          \n",
            "\n",
            "[5 rows x 3 columns]\n",
            "(60000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAEYVjSVrKCT"
      },
      "source": [
        "Perform the text generation based on the prepared dataframe. Note that the 'title' is used as input. The generated fake news will be stored in the dataframe 'generated' column.\n",
        "\n",
        "The dataframe is saved to storage to be used for further use in the follow up notebooks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q1fuOFURlwP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a4a3c010c1994448877c35e46acc5e11",
            "3cce92d408d14a13a12ef3f4b4772685",
            "8754f9e335044e02886d239c7dc32fed",
            "808f4f4328d548fbb9652836efcd74d6",
            "d9c658d717dc45c38665a77b573821d8",
            "be9aa0a4dcac403db00cc87c878291db",
            "df748b53e73d4f90b18ef20bb701c25b",
            "12973eb45b7b4a2b8f75998395b46fda"
          ]
        },
        "outputId": "797f5f75-77f4-4d0f-d2b6-13e75d80f52c"
      },
      "source": [
        "if GENERATE_TEXT:\n",
        "    text_list = None\n",
        "    generated = []\n",
        "\n",
        "    for index, row in tqdm(zip(range(total_generate_samples), df.iterrows()), total = total_generate_samples):\n",
        "        index += 1\n",
        "\n",
        "        if text_list is None:\n",
        "            text_list = []\n",
        "\n",
        "        # Prep input text\n",
        "        text_list.append(task_name + row[1]['title'])\n",
        "        \n",
        "        if index % GENERATE_BATCH_SIZE == 0:\n",
        "            # Batch Encode with Special Tokens\n",
        "            textlist_encoded = t5_tokenizer.batch_encode_plus(text_list, add_special_tokens = True, max_length = MAX_LEN, padding = True, truncation = True, return_tensors = 'tf')\n",
        "            \n",
        "            input_ids = textlist_encoded['input_ids']\n",
        "            \n",
        "            # Generate FakeNews\n",
        "            generated_fakenews = model.generate(input_ids, \n",
        "                                                max_length = MAX_LEN, \n",
        "                                                top_p = 0.95, \n",
        "                                                top_k = 256, \n",
        "                                                temperature = 1.1,\n",
        "                                                num_beams = 1, \n",
        "                                                num_return_sequences = 1, \n",
        "                                                repetition_penalty = 1.1)\n",
        "            \n",
        "            for mapping in generated_fakenews.numpy():\n",
        "                generated.append(t5_tokenizer.decode(mapping))\n",
        "\n",
        "            # Reset Text List\n",
        "            text_list = []\n",
        "\n",
        "    # Generate Final File\n",
        "    df['generated'] = generated\n",
        "    df.to_csv(WORK_DIR + 'generated_fake_news.csv')\n",
        "    print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4a3c010c1994448877c35e46acc5e11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}