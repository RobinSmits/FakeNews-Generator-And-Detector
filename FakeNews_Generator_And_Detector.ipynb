{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FakeNews_Generator_And_Detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPYiggaprH+zCtRJeDad0tH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77550a537a2d4a1cbd90c2115d483e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3111e026f1b44cac9d879706a1b1b0a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_87225eb492d348b8b442a6c1fc5d417a",
              "IPY_MODEL_9fcf4b11084b4cc495282cf1277318c0"
            ]
          }
        },
        "3111e026f1b44cac9d879706a1b1b0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87225eb492d348b8b442a6c1fc5d417a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_938f512d290148d88fd62da02decfd12",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7600,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7600,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15056998dcee4fe6bb611a5e3526ef9c"
          }
        },
        "9fcf4b11084b4cc495282cf1277318c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2e01c7f124d4337b40f180c4b7d7fba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7600/7600 [00:01&lt;00:00, 4229.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ebf3b328da8479db822a72875ffc1f3"
          }
        },
        "938f512d290148d88fd62da02decfd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15056998dcee4fe6bb611a5e3526ef9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2e01c7f124d4337b40f180c4b7d7fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ebf3b328da8479db822a72875ffc1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2231069dc234143b12ca6076e0e7071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dcb2d42bca6c4feba5deec0d2f865ae4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0083a5ee271542c9a4375c6106be9275",
              "IPY_MODEL_f815b75cc7fc4e019bf3b0c80eb5a407"
            ]
          }
        },
        "dcb2d42bca6c4feba5deec0d2f865ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0083a5ee271542c9a4375c6106be9275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67abf9b8e94f4ee8b2acf6314a2a8b04",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7600,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7600,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2dca443ac9b4352af93c7fba5a7c1c5"
          }
        },
        "f815b75cc7fc4e019bf3b0c80eb5a407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3926a22f1c224458b7bbc3a3d6a12ae7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7600/7600 [2:10:56&lt;00:00,  1.03s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef6f275aabf94d808503e0db02cbae3a"
          }
        },
        "67abf9b8e94f4ee8b2acf6314a2a8b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2dca443ac9b4352af93c7fba5a7c1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3926a22f1c224458b7bbc3a3d6a12ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef6f275aabf94d808503e0db02cbae3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f2b1f32185146359222b4d0fdb4479f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6e50ac37ca74b9f9bb61729f4628867",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2071943975aa460f9fb9163c293db3d6",
              "IPY_MODEL_0e83456d4d7546a7b2e6caf2d3789357"
            ]
          }
        },
        "f6e50ac37ca74b9f9bb61729f4628867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2071943975aa460f9fb9163c293db3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_801d99ca808a41f98152d5ebb6c2c685",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7600,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7600,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3da3366ebaf435db44771d8170a2159"
          }
        },
        "0e83456d4d7546a7b2e6caf2d3789357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50997c27aa6647678d853756785996f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7600/7600 [00:06&lt;00:00, 1098.95it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f197d51628a47a0bb88f43af3cf811c"
          }
        },
        "801d99ca808a41f98152d5ebb6c2c685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3da3366ebaf435db44771d8170a2159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50997c27aa6647678d853756785996f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f197d51628a47a0bb88f43af3cf811c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9343f9eb536c4515aba8bb007b651ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ef10b63b0d2d45438e4f58f00e884534",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ed2fb94b5dd45d881032e3d8ff2b1bb",
              "IPY_MODEL_6cb96d0bb0584d5cb9f6bc8fc7306526"
            ]
          }
        },
        "ef10b63b0d2d45438e4f58f00e884534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ed2fb94b5dd45d881032e3d8ff2b1bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_55be51ef24e94613987fcf35aa91c7dc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 657434796,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 657434796,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_278663af868140e1bcf3077eb5fb448d"
          }
        },
        "6cb96d0bb0584d5cb9f6bc8fc7306526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84ab5f15fe354a20bbf5bc7f0db8d5f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 657M/657M [00:07&lt;00:00, 88.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54519985f1f44f21bd816da73e7fc278"
          }
        },
        "55be51ef24e94613987fcf35aa91c7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "278663af868140e1bcf3077eb5fb448d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84ab5f15fe354a20bbf5bc7f0db8d5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54519985f1f44f21bd816da73e7fc278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobinSmits/FakeNews-Generator-And-Detector/blob/main/FakeNews_Generator_And_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F699OjelNmKc"
      },
      "source": [
        "In this last notebook we will use the 'test' part of the 'ag_news_subset' dataset. It contains 7600 rows with data that both the T5 and RoBERTa model have never seen before.\n",
        "\n",
        "We will again use the T5 model to use the 'title' as input and generate fake news. The generated output is stored in the file 't5_generated_fake_news_final.csv'.\n",
        "\n",
        "As a final and last step the RoBERTa model will classify the input into real or fake news."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFLz1oijbeuR",
        "outputId": "bd8a1df7-b25e-48d9-9622-0706c1d0e4a3"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Install Specific Versions\n",
        "!pip install tensorflow==2.3.1\n",
        "!pip install tensorflow-datasets==4.1.0\n",
        "!pip install transformers==4.0.0\n",
        "!pip install sentencepiece==0.1.94\n",
        "\n",
        "# Import Packages\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import *\n",
        "import sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.33.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (2.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.1) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow==2.3.1) (50.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.0.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.4.0)\n",
            "Requirement already satisfied: tensorflow-datasets==4.1.0 in /usr/local/lib/python3.6/dist-packages (4.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.25.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (3.12.4)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (20.3.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==4.1.0) (0.3.3)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets==4.1.0) (3.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.1.0) (1.52.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==4.1.0) (50.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.1.0) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.1.0) (2.10)\n",
            "Requirement already satisfied: transformers==4.0.0 in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (20.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2020.11.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.0) (2.4.7)\n",
            "Requirement already satisfied: sentencepiece==0.1.94 in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuBfy07APN5y"
      },
      "source": [
        "I've created and tested these notebooks on Google Colab Pro and used Google Drive to store and load any files created. \n",
        "\n",
        "If you run the code locally on a computer then modify the 'WORK_DIR' accordingly. Google Drive will not be needed in that case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RjCDJ7YzUdX",
        "outputId": "7be82f78-1948-42a2-b176-73875fa025ad"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set Folder to use...\n",
        "WORK_DIR = '/content/drive/My Drive/fake_news/'\n",
        "os.makedirs(WORK_DIR, exist_ok = True) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmggOdZ4PjeJ"
      },
      "source": [
        "Next we set some config for the device to use (Note: TPU to be added/tested in the future.) We also set the necessary constants. \n",
        "\n",
        "And all the necessary information for the T5 and RoBERTa models will be set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7jUGKre059v",
        "outputId": "d1d17872-d3db-4859-9c5f-1a46c5dd9416"
      },
      "source": [
        "# Set strategy choice\n",
        "USE_GPU = True\n",
        "USE_CPU = False\n",
        "\n",
        "# Set strategy with config. Our code should run on all.\n",
        "if USE_GPU:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device = \"/gpu:0\")\n",
        "if USE_CPU:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device = \"/cpu:0\")\n",
        "\n",
        "# Constants\n",
        "MAX_LEN = 512\n",
        "VERBOSE = 1\n",
        "\n",
        "# Batch Size\n",
        "GENERATE_BATCH_SIZE = 38 * strategy.num_replicas_in_sync\n",
        "PREDICT_BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "print(f'Predict Batch Size: {PREDICT_BATCH_SIZE}')\n",
        "print(f'Generate Batch Size: {GENERATE_BATCH_SIZE}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predict Batch Size: 16\n",
            "Generate Batch Size: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uo-X6tmsIfo",
        "outputId": "91ea3b2c-6ac3-4374-be00-54b44dafbe4c"
      },
      "source": [
        "# Set T5 Type\n",
        "t5_size = 't5-base'\n",
        "print(f'T5 Model Type: {t5_size}')\n",
        "\n",
        "# Set T5 Task Name\n",
        "task_name = 'generate fake news: '\n",
        "print(f'T5 Task Name: {task_name}')\n",
        "\n",
        "# Set T5 Config\n",
        "t5_config = T5Config.from_pretrained(t5_size)\n",
        "\n",
        "# Set T5 Tokenizer\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(t5_size, return_dict = True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T5 Model Type: t5-base\n",
            "T5 Task Name: generate fake news: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ2_4tNAsvuq",
        "outputId": "d5b54571-6f46-4f9f-e804-e0a4ad2a9347"
      },
      "source": [
        "# Set RoBERTa Type\n",
        "roberta_type = 'roberta-base'\n",
        "print(f'RoBERTa Model Type: {roberta_type}')\n",
        "\n",
        "# Set RoBERTa Config\n",
        "roberta_config = RobertaConfig.from_pretrained(roberta_type, num_labels = 2)  # Binary classification so set num_labels = 2\n",
        "\n",
        "# Set RoBERTa Tokenizer\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(roberta_type, \n",
        "                                             return_dict = True,\n",
        "                                             add_prefix_space = True,\n",
        "                                             do_lower_case = True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RoBERTa Model Type: roberta-base\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFRgK6UkQLrh"
      },
      "source": [
        "For Generation we will use the 'test' set part of the Tensorflow Dataset 'ag_news_subset'. It contains a train set of 120K rows and a test set of 7600 rows.\n",
        "\n",
        "Both the T5 and RoBERTa model have never been trained on the 'test' set part of the data. It is completely unseen to both models.\n",
        "\n",
        "Each row contains a 'title' which is a news paper headline and a 'description' which is a short part of the news paper article.\n",
        "\n",
        "The 'title' will be used as input for the T5 model to generate the fake news.\n",
        "\n",
        "!! Note: I've experienced multiple times that on the initial download of the dataset an error occurs. If you run it again it will just work..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw1Xoc0GeFYG",
        "outputId": "0bca833e-bd94-44fb-8245-9597f18c628a"
      },
      "source": [
        "# Get data and datasets\n",
        "ag_news_ds, info = tfds.load('ag_news_subset', split = ['test'], with_info = True, shuffle_files = True, as_supervised = False)\n",
        "test_ds = ag_news_ds[0]\n",
        "\n",
        "# Dataset features\n",
        "print(info.features)\n",
        "\n",
        "# Samples\n",
        "total_samples = info.splits['test'].num_examples \n",
        "print(f'Total Samples: {total_samples}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/ag_news_subset/1.0.0\n",
            "INFO:absl:Reusing dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split ['test'], from /root/tensorflow_datasets/ag_news_subset/1.0.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FeaturesDict({\n",
            "    'description': Text(shape=(), dtype=tf.string),\n",
            "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
            "    'title': Text(shape=(), dtype=tf.string),\n",
            "})\n",
            "Total Samples: 7600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITF-Z7I6RVXR"
      },
      "source": [
        "Next map the test_ds to use only the 'description' and 'title'. The test_ds is used for generating the fake news."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mhpLXSKCOrK"
      },
      "source": [
        "# Map and Decode Split(s)\n",
        "def decode_example(example):\n",
        "    decoded_example = info.features.decode_example(example)\n",
        "    \n",
        "    description = decoded_example['description']\n",
        "    title = decoded_example['title']\n",
        "    \n",
        "    return title, description\n",
        "\n",
        "# Map\n",
        "test_ds = test_ds.map(decode_example, num_parallel_calls = tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCHCNR_lRm7V"
      },
      "source": [
        "Create the Keras Model to be used for T5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WmEQKkVSkzZ"
      },
      "source": [
        "class KerasTFT5ForConditionalGeneration(TFT5ForConditionalGeneration):\n",
        "    def __init__(self, *args, log_dir = None, cache_dir = None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n",
        "    \n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        x = data[0]\n",
        "        y = x['labels']\n",
        "        y = tf.reshape(y, [-1, 1])\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = self(x, training = True)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            loss = tf.reduce_mean(loss)\n",
        "            grads = tape.gradient(loss, self.trainable_variables)\n",
        "            \n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "        self.loss_tracker.update_state(loss)        \n",
        "        self.compiled_metrics.update_state(y, logits)\n",
        "        metrics = {m.name: m.result() for m in self.metrics}\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "    def test_step(self, data):\n",
        "        x = data[0]\n",
        "        y = x[\"labels\"]\n",
        "        y = tf.reshape(y, [-1, 1])\n",
        "        output = self(x, training = False)\n",
        "        loss = output[0]\n",
        "        loss = tf.reduce_mean(loss)\n",
        "        logits = output[1]\n",
        "        \n",
        "        self.loss_tracker.update_state(loss)\n",
        "        metrics = self.compiled_metrics.update_state(y, logits)\n",
        "        \n",
        "        return metrics"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMPlLI2NRzcv"
      },
      "source": [
        "Next create the model and load the weights file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STDVTd6gUmN3",
        "outputId": "88c68ce5-b4c7-4d0f-ea32-6252085fbbcf"
      },
      "source": [
        "# Create Model\n",
        "with strategy.scope():\n",
        "    model = KerasTFT5ForConditionalGeneration.from_pretrained(t5_size, config = t5_config)\n",
        "    model.compile(optimizer = tf.keras.optimizers.Adam(), \n",
        "                  metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name = 'accuracy')])\n",
        "\n",
        "# Summary\n",
        "model.summary()\n",
        "\n",
        "# Load Weights\n",
        "model.load_weights(WORK_DIR + 't5_base_model.h5')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at t5-base were not used when initializing KerasTFT5ForConditionalGeneration: ['decoder/block_._0/layer_._1/EncDecAttention/relative_attention_bias/embeddings:0']\n",
            "- This IS expected if you are initializing KerasTFT5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing KerasTFT5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of KerasTFT5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['loss']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"keras_tf_t5for_conditional_generation\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "shared (TFSharedEmbeddings)  multiple                  24674304  \n",
            "_________________________________________________________________\n",
            "encoder (TFT5MainLayer)      multiple                  84954240  \n",
            "_________________________________________________________________\n",
            "decoder (TFT5MainLayer)      multiple                  113275008 \n",
            "_________________________________________________________________\n",
            "loss (Mean)                  multiple                  2         \n",
            "=================================================================\n",
            "Total params: 222,903,554\n",
            "Trainable params: 222,903,552\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2P-u98LSWMt"
      },
      "source": [
        "Use the test_ds to prepare the final dataframe that will be saved to disk after the fake news generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "77550a537a2d4a1cbd90c2115d483e66",
            "3111e026f1b44cac9d879706a1b1b0a4",
            "87225eb492d348b8b442a6c1fc5d417a",
            "9fcf4b11084b4cc495282cf1277318c0",
            "938f512d290148d88fd62da02decfd12",
            "15056998dcee4fe6bb611a5e3526ef9c",
            "c2e01c7f124d4337b40f180c4b7d7fba",
            "7ebf3b328da8479db822a72875ffc1f3"
          ]
        },
        "id": "RLG7RuOwXOhs",
        "outputId": "b2b4d325-15c2-406b-8643-ba458d3dd0ea"
      },
      "source": [
        "# Placeholders\n",
        "titles, descriptions = [], []\n",
        " \n",
        "# Process Tensorflow Dataset as Numpy ... otherwise not possible to process tokenization.\n",
        "generate_ds_numpy = tfds.as_numpy(test_ds)\n",
        "\n",
        "for index, sample in tqdm(zip(range(total_samples), generate_ds_numpy), total = total_samples):\n",
        "    # Get title and description as strings\n",
        "    titles.append(sample[0].decode('utf-8'))             # title\n",
        "    descriptions.append(sample[1].decode('utf-8'))       # description = \n",
        "\n",
        "# Create Dataframe\n",
        "df = pd.DataFrame()\n",
        "df['title'] = titles\n",
        "df['description'] = descriptions\n",
        "df['generated'] = ''\n",
        "\n",
        "# Summary\n",
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77550a537a2d4a1cbd90c2115d483e66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                                               title  ... generated\n",
            "0               Carolina's Davis Done for the Season  ...          \n",
            "1      Philippine Rebels Free Troops, Talks in Doubt  ...          \n",
            "2          New Rainbow Six Franchise for Spring 2005  ...          \n",
            "3                          Kiwis heading for big win  ...          \n",
            "4  Shelling, shooting resumes in breakaway Georgi...  ...          \n",
            "\n",
            "[5 rows x 3 columns]\n",
            "(7600, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nkk4evffSkLN"
      },
      "source": [
        "Perform the text generation based on the prepared dataframe. Note that the 'title' is used as input. The generated fake news will be stored in the dataframe 'generated' column.\n",
        "\n",
        "The dataframe is saved to storage for reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207,
          "referenced_widgets": [
            "d2231069dc234143b12ca6076e0e7071",
            "dcb2d42bca6c4feba5deec0d2f865ae4",
            "0083a5ee271542c9a4375c6106be9275",
            "f815b75cc7fc4e019bf3b0c80eb5a407",
            "67abf9b8e94f4ee8b2acf6314a2a8b04",
            "b2dca443ac9b4352af93c7fba5a7c1c5",
            "3926a22f1c224458b7bbc3a3d6a12ae7",
            "ef6f275aabf94d808503e0db02cbae3a"
          ]
        },
        "id": "0q1fuOFURlwP",
        "outputId": "4ef8c2fb-882f-4d4f-8588-707c58a93b3e"
      },
      "source": [
        "text_list = None\n",
        "generated = []\n",
        "\n",
        "for index, row in tqdm(zip(range(total_samples), df.iterrows()), total = total_samples):\n",
        "    index += 1\n",
        "\n",
        "    if text_list is None:\n",
        "        text_list = []\n",
        "\n",
        "    # Prep input text\n",
        "    text_list.append(task_name + row[1]['title'])\n",
        "    \n",
        "    if index % GENERATE_BATCH_SIZE == 0:\n",
        "        # Batch Encode with Special Tokens\n",
        "        textlist_encoded = t5_tokenizer.batch_encode_plus(text_list, add_special_tokens = True, max_length = MAX_LEN, padding = True, truncation = True, return_tensors = 'tf')\n",
        "        \n",
        "        input_ids = textlist_encoded['input_ids']\n",
        "        \n",
        "        # Generate FakeNews\n",
        "        generated_fakenews = model.generate(input_ids, \n",
        "                                          max_length = MAX_LEN, \n",
        "                                          top_p = 0.95, \n",
        "                                          top_k = 256, \n",
        "                                          temperature = 1.1,\n",
        "                                          num_beams = 1, \n",
        "                                          num_return_sequences = 1, \n",
        "                                          repetition_penalty = 1.1)\n",
        "        \n",
        "        for mapping in generated_fakenews.numpy():\n",
        "            generated.append(t5_tokenizer.decode(mapping, skip_special_tokens = True))\n",
        "\n",
        "        # Reset Text List\n",
        "        text_list = []\n",
        "\n",
        "# Generate Final File\n",
        "df['generated'] = generated\n",
        "df.to_csv(WORK_DIR + 't5_generated_fake_news_final.csv')\n",
        "print(df.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2231069dc234143b12ca6076e0e7071",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                                               title  ...                                          generated\n",
            "0               Carolina's Davis Done for the Season  ...  The Carolina Panthers' defensive end, who was ...\n",
            "1      Philippine Rebels Free Troops, Talks in Doubt  ...  Philippine rebels freed their troops from the ...\n",
            "2          New Rainbow Six Franchise for Spring 2005  ...  The Rainbow Six franchise will be released in ...\n",
            "3                          Kiwis heading for big win  ...  The Kiwis are heading for a big win in the fir...\n",
            "4  Shelling, shooting resumes in breakaway Georgi...  ...  AFP - A shelling operation and a shooting in t...\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgId77qon6rh"
      },
      "source": [
        "### RoBERTa FakeNews Detector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAO8eLZoS5B_"
      },
      "source": [
        "Next we define a function to process the 't5_generated_fake_news_final.csv' which is loaded as a Pandas Dataframe. We loop through all rows and from each row we use the columns 'description' and 'generated' as input for the RoBERTa model.\n",
        "\n",
        "The 'description' input will be labelled with 0. The 'generated' input will be labelled with 1. The 'title' which we used in the T5 model is not used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oL4C_tGV2P0"
      },
      "source": [
        "def create_dataset(df):\n",
        "    number_of_samples = df.shape[0]\n",
        "    total_samples = 2 * df.shape[0]\n",
        "\n",
        "    # Placeholders input\n",
        "    input_ids = np.zeros((total_samples, MAX_LEN), dtype = 'int32')\n",
        "    input_masks = np.zeros((total_samples, MAX_LEN), dtype = 'int32')\n",
        "    labels = np.zeros((total_samples, ), dtype = 'int32')\n",
        "\n",
        "    for index, row in tqdm(zip(range(0, total_samples, 2), df.iterrows()), total = number_of_samples):\n",
        "        \n",
        "        # Get title and description as strings\n",
        "        description = row[1]['description']\n",
        "        generated = row[1]['generated']\n",
        "\n",
        "        # Process Description - Set Label for real as 0\n",
        "        input_encoded = roberta_tokenizer.encode_plus(description, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "        input_ids_sample = input_encoded['input_ids']\n",
        "        input_ids[index,:len(input_ids_sample)] = input_ids_sample\n",
        "        attention_mask_sample = input_encoded['attention_mask']\n",
        "        input_masks[index,:len(attention_mask_sample)] = attention_mask_sample\n",
        "        labels[index] = 0\n",
        "\n",
        "        # Process Generated - Set Label for fake as 1\n",
        "        input_encoded = roberta_tokenizer.encode_plus(generated, add_special_tokens = True, max_length = MAX_LEN, truncation = True)\n",
        "        input_ids_sample = input_encoded['input_ids']\n",
        "        input_ids[index+1,:len(input_ids_sample)] = input_ids_sample\n",
        "        attention_mask_sample = input_encoded['attention_mask']\n",
        "        input_masks[index+1,:len(attention_mask_sample)] = attention_mask_sample\n",
        "        labels[index+1] = 1\n",
        "\n",
        "    # Create DatasetDictionary structure is also preserved.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': input_ids, 'attention_mask': input_masks}, labels))\n",
        "\n",
        "    # Return Dataset\n",
        "    return dataset"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXxmgFUeTUMY"
      },
      "source": [
        "We load the csv file and call the previously defined function to generate our final Tensorflow Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEInCT9U6G40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "2f2b1f32185146359222b4d0fdb4479f",
            "f6e50ac37ca74b9f9bb61729f4628867",
            "2071943975aa460f9fb9163c293db3d6",
            "0e83456d4d7546a7b2e6caf2d3789357",
            "801d99ca808a41f98152d5ebb6c2c685",
            "e3da3366ebaf435db44771d8170a2159",
            "50997c27aa6647678d853756785996f1",
            "2f197d51628a47a0bb88f43af3cf811c"
          ]
        },
        "outputId": "959212a5-5052-4122-f35d-23e44b8fcfc7"
      },
      "source": [
        "# Import Generated Fake News\n",
        "df = pd.read_csv(WORK_DIR + 't5_generated_fake_news_final.csv')\n",
        "\n",
        "# Show Sizes\n",
        "print(f'Test DF Shape: {df.shape}')\n",
        "\n",
        "# Create Validation Dataset\n",
        "test_dataset = create_dataset(df)\n",
        "test_dataset = test_dataset.batch(PREDICT_BATCH_SIZE)\n",
        "test_dataset = test_dataset.repeat(-1)\n",
        "test_dataset = test_dataset.prefetch(128)\n",
        "\n",
        "# Steps\n",
        "test_steps = (df.shape[0] * 2) // PREDICT_BATCH_SIZE\n",
        "print(f'Test Steps: {test_steps}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test DF Shape: (7600, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f2b1f32185146359222b4d0fdb4479f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7600.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Steps: 950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hupv0MiTrz4"
      },
      "source": [
        "Define a function to create and compile the RoBERTa base model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZMVCk9XRC3u"
      },
      "source": [
        "def build_model():\n",
        "    # Create Model\n",
        "    with strategy.scope():      \n",
        "        model = TFRobertaForSequenceClassification.from_pretrained(roberta_type, config = roberta_config)\n",
        "        \n",
        "        optimizer = tf.keras.optimizers.Adam()\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "        model.compile(optimizer = optimizer, loss = loss, metrics = [metric])        \n",
        "        \n",
        "        return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnDlQEKTVAKc"
      },
      "source": [
        "Create the model and load the weights file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfG_x1-9X2P4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "9343f9eb536c4515aba8bb007b651ae5",
            "ef10b63b0d2d45438e4f58f00e884534",
            "4ed2fb94b5dd45d881032e3d8ff2b1bb",
            "6cb96d0bb0584d5cb9f6bc8fc7306526",
            "55be51ef24e94613987fcf35aa91c7dc",
            "278663af868140e1bcf3077eb5fb448d",
            "84ab5f15fe354a20bbf5bc7f0db8d5f2",
            "54519985f1f44f21bd816da73e7fc278"
          ]
        },
        "outputId": "f75d7ae4-2d63-4387-ef0b-2b58ca6c3817"
      },
      "source": [
        "# Create Model\n",
        "model = build_model()\n",
        "\n",
        "# Summary\n",
        "model.summary()\n",
        "\n",
        "# Load Weights\n",
        "model.load_weights(WORK_DIR + 'roberta_base_model.h5')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9343f9eb536c4515aba8bb007b651ae5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaForSequenceClassification: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_roberta_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "roberta (TFRobertaMainLayer) multiple                  124645632 \n",
            "_________________________________________________________________\n",
            "classifier (TFRobertaClassif multiple                  592130    \n",
            "=================================================================\n",
            "Total params: 125,237,762\n",
            "Trainable params: 125,237,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEG6Ws5YVbC2"
      },
      "source": [
        "Next lets first evaluate the test set and see how well the RoBERTa model can classify the generated data.\n",
        "\n",
        "With an evaluation accuracy of around 97% the RoBERTa model performs a nice job of classifying the real and fake news."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2nJbQD7eato",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6885eb7-7b94-4e03-cb5f-9b273ce4ddab"
      },
      "source": [
        "# Evaluate Dataset\n",
        "eval = model.evaluate(test_dataset, steps = test_steps, verbose = 1)\n",
        "print(f'Detection Accuracy: {eval[1] * 100}%')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "950/950 [==============================] - 329s 347ms/step - loss: 0.0693 - accuracy: 0.9763\n",
            "Detection Accuracy: 97.63157963752747%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfc8vtulVrfa"
      },
      "source": [
        "We can also perform prediction with the test set. This is basically the same action as the evaluation. However evaluation will give us back the evaluation metrics where as prediction will give us back the raw predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l6GrnOCKKOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1d99ec-01af-4012-9a85-3e292352a3e6"
      },
      "source": [
        " # Predict Dataset\n",
        "preds = model.predict(test_dataset, steps = test_steps, verbose = 1)\n",
        "\n",
        "# Raw Predictions\n",
        "print(preds.logits)\n",
        "\n",
        "# Probabilities\n",
        "print(tf.nn.softmax(preds.logits).numpy())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "950/950 [==============================] - 326s 343ms/step\n",
            "[[ 4.548599   -4.0588593 ]\n",
            " [-4.5663304   4.1195855 ]\n",
            " [ 4.5302153  -4.0765967 ]\n",
            " ...\n",
            " [-4.6145864   4.2126226 ]\n",
            " [ 0.18418173 -0.21952124]\n",
            " [-3.9972808   3.5839248 ]]\n",
            "[[9.9981731e-01 1.8270443e-04]\n",
            " [1.6892007e-04 9.9983108e-01]\n",
            " [9.9981719e-01 1.8282258e-04]\n",
            " ...\n",
            " [1.4666549e-04 9.9985337e-01]\n",
            " [5.9957701e-01 4.0042299e-01]\n",
            " [5.0968624e-04 9.9949026e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRTMOJEQpWTY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}